"""
ä»è¯­æ–‡PDFè‡ªåŠ¨æå–è¯¾æ–‡ä¿¡æ¯å¹¶ç”ŸæˆCSV
"""
import os
import sys
import re
from pathlib import Path
import pandas as pd

sys.path.append(str(Path(__file__).parent))

try:
    import pdfplumber
except ImportError:
    print("âŒ è¯·å…ˆå®‰è£…: pip install pdfplumber")
    sys.exit(1)

class ChineseTextbookExtractor:
    """è¯­æ–‡è¯¾æœ¬å†…å®¹æå–å™¨"""
    
    # PDFæ–‡ä»¶æ˜ å°„
    PDF_MAP = {
        ('åˆä¸€', 'ä¸Š'): 'ã€äººæ•™ç‰ˆäº”å››åˆ¶ã€‘ä¸ƒå¹´çº§ä¸Šå†Œ(2024ç§‹ç‰ˆ)è¯­æ–‡ç”µå­è¯¾æœ¬.pdf',
        ('åˆä¸€', 'ä¸‹'): 'ã€äººæ•™ç‰ˆäº”å››åˆ¶ã€‘ä¸ƒå¹´çº§ä¸‹å†Œ(2025æ˜¥ç‰ˆ)è¯­æ–‡ç”µå­è¯¾æœ¬.pdf',
        ('åˆäºŒ', 'ä¸Š'): 'ã€äººæ•™ç‰ˆäº”å››åˆ¶ã€‘å…«å¹´çº§ä¸Šå†Œ(2025ç§‹ç‰ˆ)è¯­æ–‡ç”µå­è¯¾æœ¬.pdf',
        ('åˆäºŒ', 'ä¸‹'): 'ã€äººæ•™ç‰ˆäº”å››åˆ¶ã€‘å…«å¹´çº§ä¸‹å†Œè¯­æ–‡ç”µå­è¯¾æœ¬.pdf',
        ('åˆä¸‰', 'ä¸Š'): 'ã€äººæ•™ç‰ˆäº”å››åˆ¶ã€‘ä¹å¹´çº§ä¸Šå†Œè¯­æ–‡ç”µå­è¯¾æœ¬.pdf',
        ('åˆä¸‰', 'ä¸‹'): 'ã€äººæ•™ç‰ˆäº”å››åˆ¶ã€‘ä¹å¹´çº§ä¸‹å†Œè¯­æ–‡ç”µå­è¯¾æœ¬.pdf',
    }
    
    def __init__(self):
        self.pdf_base_path = Path(__file__).parent.parent / 'è¯¾æœ¬' / 'è¯­æ–‡'
        self.output_path = Path(__file__).parent.parent / 'course' / 'è¯­æ–‡'
    
    def extract_toc_from_pdf(self, pdf_path):
        """ä»PDFæå–ç›®å½•"""
        
        lessons = []
        seen_lessons = set()  # ç”¨äºå»é‡
        
        try:
            with pdfplumber.open(pdf_path) as pdf:
                # è¯»å–å‰10é¡µï¼ŒæŸ¥æ‰¾ç›®å½•
                for page_num in range(min(10, len(pdf.pages))):
                    page = pdf.pages[page_num]
                    text = page.extract_text()
                    
                    if not text:
                        continue
                    
                    # åªå¤„ç†åŒ…å«"ç›®å½•"æˆ–"ç›® å½•"çš„é¡µé¢
                    if 'ç›®' not in text or page_num > 8:
                        continue
                    
                    lines = text.split('\n')
                    
                    for line in lines:
                        line = line.strip()
                        
                        # è·³è¿‡åŒ…å«"é˜… è¯»"è¿™ç§åˆ†å¼€æ ¼å¼çš„è¡Œ
                        if 'é˜… è¯»' in line or 'è¯» ç¬¬' in line:
                            continue
                        
                        # å…ˆç§»é™¤"é˜…è¯»"å‰ç¼€ï¼ˆè¿åœ¨ä¸€èµ·çš„ï¼‰
                        line_clean = re.sub(r'^é˜…è¯»\s+', '', line)
                        
                        # åŒ¹é…å¸¦ä½œè€…çš„æ ¼å¼: "1 æ ‡é¢˜/ä½œè€… é¡µç "
                        match1 = re.match(r'^(\d+)\*?\s+(.+?)\s*/\s*(.+?)(?:\s+\d+)?$', line_clean)
                        # åŒ¹é…æ— ä½œè€…çš„æ ¼å¼: "1 æ ‡é¢˜ é¡µç "
                        match2 = re.match(r'^(\d+)\*?\s+([^/\d]+?)(?:\s+\d+)?$', line_clean)
                        
                        match = match1 or match2
                        
                        if match:
                            lesson_num = match.group(1)
                            title = match.group(2).strip()
                            author = match.group(3).strip() if len(match.groups()) >= 3 and match.group(3) else ''
                            
                            # è¿‡æ»¤æ‰éè¯¾æ–‡å†…å®¹
                            skip_keywords = ['é˜…è¯»ç»¼åˆå®è·µ', 'å†™ä½œ', 'æ•´æœ¬ä¹¦é˜…è¯»', 'ä¸“é¢˜å­¦ä¹ ', 
                                           'è¯¾å¤–å¤è¯—è¯', 'æ´»åŠ¨Â·æ¢ç©¶', 'ä»»åŠ¡', 'ç›® å½•',
                                           'å•å…ƒ', 'æ³¨ï¼š']
                            
                            if any(kw in title for kw in skip_keywords):
                                continue
                            
                            # è¿‡æ»¤å¤ªçŸ­çš„æ ‡é¢˜ï¼ˆå¯èƒ½æ˜¯è¯¯åŒ¹é…ï¼‰
                            if len(title) < 2:
                                continue
                            
                            # å¤„ç†æ ‡é¢˜ï¼ˆç§»é™¤å‰¯æ ‡é¢˜ï¼‰
                            if 'â€”â€”' in title:
                                title = title.split('â€”â€”')[0].strip()
                            
                            # å»é™¤æ ‡é¢˜æœ«å°¾çš„é¡µç 
                            title = re.sub(r'\s+\d+$', '', title)
                            
                            # å»é‡ï¼šä½¿ç”¨è¯¾ç¨‹å·+æ ‡é¢˜ä½œä¸ºå”¯ä¸€æ ‡è¯†
                            lesson_key = f"{lesson_num}_{title}"
                            if lesson_key in seen_lessons:
                                continue
                            seen_lessons.add(lesson_key)
                            
                            # ç”Ÿæˆå…³é”®è¯
                            keywords = self.generate_keywords(title, author)
                            
                            lessons.append({
                                'è¯¾ç¨‹å·': lesson_num,
                                'æ ‡é¢˜': title,
                                'ä½œè€…': author,
                                'å…³é”®è¯': keywords
                            })
        
        except Exception as e:
            print(f"  âŒ æå–å¤±è´¥: {e}")
            return []
        
        # æŒ‰è¯¾ç¨‹å·æ’åº
        lessons.sort(key=lambda x: int(x['è¯¾ç¨‹å·']))
        
        return lessons
    
    def generate_keywords(self, title, author):
        """æ ¹æ®æ ‡é¢˜å’Œä½œè€…ç”Ÿæˆå…³é”®è¯"""
        
        keywords = []
        
        # æ·»åŠ ä½œè€…
        if author and author != '':
            # æ¸…ç†ä½œè€…åï¼ˆå»æ‰ä¹¦åå·ç­‰ï¼‰
            author_clean = author.replace('ã€Š', '').replace('ã€‹', '').replace('ï¼ˆ', '').replace('ï¼‰', '')
            keywords.append(author_clean)
        
        # æ ¹æ®æ ‡é¢˜åˆ¤æ–­ä½“è£
        if 'è¯—' in title or 'è¯' in title:
            keywords.append('è¯—æ­Œ')
        elif 'æ–‡è¨€' in title or any(classic in author for classic in ['èµ„æ²»é€šé‰´', 'è®ºè¯­', 'å­Ÿå­', 'åˆ—å­']):
            keywords.append('æ–‡è¨€æ–‡')
        elif 'æ•£æ–‡' in title:
            keywords.append('æ•£æ–‡')
        elif 'å°è¯´' in title:
            keywords.append('å°è¯´')
        elif 'è®°' in title:
            keywords.append('è®°å™æ–‡')
        elif 'è¯´' in title:
            keywords.append('è¯´æ˜æ–‡')
        else:
            keywords.append('ç°ä»£æ–‡')
        
        return '|'.join(keywords) if keywords else ''
    
    def process_all_textbooks(self):
        """å¤„ç†æ‰€æœ‰è¯­æ–‡è¯¾æœ¬"""
        
        print("\n" + "="*80)
        print("  ğŸ“š è¯­æ–‡è¯¾æœ¬CSVç”Ÿæˆ")
        print("="*80 + "\n")
        
        for (grade, semester), pdf_name in self.PDF_MAP.items():
            pdf_path = self.pdf_base_path / pdf_name
            
            if not pdf_path.exists():
                print(f"âš ï¸  æ–‡ä»¶ä¸å­˜åœ¨: {pdf_name}")
                continue
            
            print(f"\nğŸ“– å¤„ç†: {grade}{semester}å­¦æœŸ")
            print(f"   PDF: {pdf_name}")
            
            # æå–ç›®å½•
            lessons = self.extract_toc_from_pdf(pdf_path)
            
            if not lessons:
                print(f"   âŒ æœªæå–åˆ°è¯¾æ–‡ä¿¡æ¯")
                continue
            
            print(f"   âœ… æå–åˆ° {len(lessons)} ç¯‡è¯¾æ–‡")
            
            # æ˜¾ç¤ºå‰3ç¯‡
            for i, lesson in enumerate(lessons[:3], 1):
                print(f"      {i}. {lesson['æ ‡é¢˜']} / {lesson['ä½œè€…']}")
            if len(lessons) > 3:
                print(f"      ...")
            
            # ç”ŸæˆCSV
            csv_filename = f"è¯­æ–‡-{grade}{semester}.csv"
            csv_path = self.output_path / csv_filename
            
            # æ„å»ºDataFrame
            data = []
            for lesson in lessons:
                data.append({
                    'å¹´çº§': grade,
                    'å­¦æœŸ': semester,
                    'å­¦ç§‘': 'è¯­æ–‡',
                    'è¯¾ç¨‹å·': lesson['è¯¾ç¨‹å·'],
                    'æ ‡é¢˜': lesson['æ ‡é¢˜'],
                    'å…³é”®è¯': lesson['å…³é”®è¯']
                })
            
            df = pd.DataFrame(data)
            df.to_csv(csv_path, index=False, encoding='utf-8-sig')
            
            print(f"   ğŸ’¾ å·²ä¿å­˜: {csv_filename}\n")
        
        print("\n" + "="*80)
        print("  âœ… CSVç”Ÿæˆå®Œæˆ")
        print("="*80)
        print("\nğŸ’¡ ä¸‹ä¸€æ­¥ï¼š")
        print("  1. æ£€æŸ¥ç”Ÿæˆçš„CSVæ–‡ä»¶")
        print("  2. å¦‚æœ‰éœ€è¦ï¼Œæ‰‹åŠ¨ä¿®æ­£æ ‡é¢˜å’Œå…³é”®è¯")
        print("  3. è¿è¡Œ batch_import_csv.py å¯¼å…¥æ•°æ®åº“\n")

def main():
    extractor = ChineseTextbookExtractor()
    extractor.process_all_textbooks()

if __name__ == '__main__':
    main()

